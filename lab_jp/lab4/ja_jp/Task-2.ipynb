{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# タスク 2: Amazon Bedrock ナレッジベースと Retrieve API を使用して質問応答アプリケーションを構築する\n",
    "\n",
    "このタスクでは、Amazon Bedrock ナレッジベースと **Retrieve API** を使用して質問応答アプリケーションを構築します。ここでは、ナレッジベースにクエリを実行して、類似検索に基づいて必要な数のドキュメントチャンクを取得します。次に、関連ドキュメントでプロンプトを強化し、Amazon Nova Lite への入力として機能するクエリを実行して応答を生成します。\n",
    "\n",
    "ナレッジベースを使用すると、Amazon Bedrock の基盤モデル (FM) を会社のデータに安全に接続して、検索拡張生成 (RAG) を行うことができます。追加データにアクセスすることで、FM を継続的に再トレーニングしなくても、モデルがコンテキストに応じた関連性の高い正確な応答を生成できるようになります。ナレッジベースから取得された情報にはすべて出典の属性が付き、透明性を高めると共にハルシネーションを最低限に抑えます。\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-info-circle\" style=\"color:#007FAA\"></i>**詳細情報:** コンソールを使用してナレッジベースを作成する方法の詳細については、**[Amazon Bedrock ナレッジベース](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html)** を参照してください。\n",
    "\n",
    "### シナリオ\n",
    "\n",
    "検索拡張生成 (RAG) パターンを使用してソリューションを実装します。RAG は、言語モデルの外部からデータを取得し、取得データをコンテキストに追加することでプロンプトを拡張します。ここでは、ラボのプロビジョニングの一環として作成されたナレッジベースで RAG を効果的に実行します。\n",
    "    \n",
    "このノートブックで行うこと:\n",
    "\n",
    "- AnyCompany の 10K 財務報告 (合成的に生成されたデータセット) をテキストコーパスとして使用して質問応答を行います。このデータは、ラボのプロビジョニング中に既に Amazon Bedrock ナレッジベースに取り込まれています。\n",
    "- このラボ環境用に作成された既存のナレッジベースのナレッジベース ID を使用します。\n",
    "- Amazon Bedrock **Retrieve API** と LangChain 検索の両方を使用して、ナレッジベースからドキュメントを取得し、それをコンテキストとして追加して、ユーザーのクエリに回答します。\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-exclamation-circle\" style=\"color:#7C5AED\"></i> **注意:** [**Run**] メニューの [**Run All Cells**] オプションを使用するよりも、各コードセルを個別に実行することをお勧めします。すべてのセルをまとめて実行すると、カーネルがクラッシュしたり再起動したりするなど、予期しない動作が発生することがあります。セルを 1 つずつ実行することで、実行フローをより適切に制御し、潜在的なエラーを早期に検出し、コードを意図したとおりに実行することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 2.1: 環境を設定する\n",
    "\n",
    "このタスクでは、Amazon Bedrock クライアントを起動し、次の操作を実行します。\n",
    "\n",
    "- ナレッジベース ID を確認します。\n",
    "- 必要なライブラリをインポートし、必要なクライアントを設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### タスク 2.1.1: ナレッジベース ID を確認する\n",
    "\n",
    "このノートブックを実行するには、ナレッジベース ID を確認して **kb_id** 変数に割り当てて、必要なパッケージをインストールする必要があります。\n",
    "\n",
    "1. 次のコードセルを実行して、Amazon Bedrock の既存のナレッジベースの ID を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "\n",
    "session = boto3.Session()\n",
    "bedrock_client = session.client('bedrock-agent')\n",
    "\n",
    "try:\n",
    "    response = bedrock_client.list_knowledge_bases(\n",
    "        maxResults=1  # We only need to retrieve the first Knowledge Base\n",
    "    )\n",
    "    knowledge_base_summaries = response.get('knowledgeBaseSummaries', [])\n",
    "\n",
    "    if knowledge_base_summaries:\n",
    "        kb_id = knowledge_base_summaries[0]['knowledgeBaseId']\n",
    "        print(f\"Knowledge Base ID: {kb_id}\")\n",
    "    else:\n",
    "        print(\"No Knowledge Base summaries found.\")\n",
    "        \n",
    "except botocore.exceptions.ClientError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### タスク 2.1.2: Amazon Bedrock クライアントを起動する\n",
    "\n",
    "2. 次のコードセルを実行して、環境を設定するために必要なライブラリをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.client import Config\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name = region)\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\",\n",
    "                              config=bedrock_config, region_name = region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パート 1: Amazon Bedrock の基盤モデルで **Retrieve** API を使用する\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **注:** このパートでは *amazon.nova-lite-v1:0* モデルを使用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 2.2: Amazon Bedrock の基盤モデルで Retrieve API を使用する\n",
    "\n",
    "このタスクでは、Amazon Bedrock のナレッジベースによって提供される **Retrieve** API を呼び出す取得関数を定義します。こうすることにより、ユーザーのクエリが埋め込みに変換され、ナレッジベースが検索され、関連する結果が返されます。これにより、セマンティック検索結果に基づいてカスタムワークフローの構築をより細かく制御できるようになります。\n",
    "\n",
    "**Retrieve** API の出力には、**取得したテキストチャンク**、ソースデータの**ロケーションタイプ**と **URI**、検索の関連性**スコア**が含まれます。**retrievalConfiguration** の **overrideSearchType** オプションを使用することもできます。このオプションでは、**HYBRID** または **SEMANTIC** のどちらを使用するかを選択できます。\n",
    "\n",
    "デフォルトでは、最適な戦略が選択され、最も関連性の高い結果が得られます。ハイブリッド検索またはセマンティック検索を使用するようにデフォルトオプションをオーバーライドする場合は、値を **HYBRID/SEMANTIC** に設定できます。\n",
    "\n",
    "<!-- ![retrieveAPI](./images/retrieveAPI.png) -->\n",
    "<img src=\"images/retrieveAPI.png\" width=50% height=20% />\n",
    "\n",
    "**画像の説明: 上の図は、ラボ環境のカスタマイズされた RAG ワークフローを示しています。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 次のコードセルを実行して、**Retrieve** API を呼び出す、**取得**関数を定義します:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, kbId, numberOfResults=5):\n",
    "    return bedrock_agent_client.retrieve(\n",
    "        retrievalQuery= {\n",
    "            'text': query\n",
    "        },\n",
    "        knowledgeBaseId=kbId,\n",
    "        retrievalConfiguration= {\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': numberOfResults,\n",
    "                'overrideSearchType': \"HYBRID\", # optional\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### タスク 2.2.1: 初期化された LLM からの応答のクエリを行う前にナレッジベース ID を初期化する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このタスクでは、**Retrieve** API を呼び出し、**ナレッジベース ID**、**結果の数**、**クエリ**をパラメータとして渡します。\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **注:** 返された各テキストチャンクの関連スコアを表示できます。このスコアは、どの程度一致しているかという観点からクエリとの相関関係を示しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 次のコードセルを実行し、**ナレッジベース ID**、**結果の数**、**クエリ**をパラメータとして渡して、**Retrieve** API を呼び出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "query = \"2022年12月31日現在のAnyCompanyのtotal operating lease liabilitiesとtotal sublease incomeはいくらでしたか？\"\n",
    "response = retrieve(query, kb_id, 5)\n",
    "retrievalResults = response['retrievalResults']\n",
    "pp.pprint(retrievalResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### タスク 2.2.2: **Retrieve** API の応答からテキストチャンクを抽出する\n",
    "\n",
    "このタスクでは、**Retrieve** API の応答からテキストチャンクを抽出します。\n",
    "\n",
    "5. 次の 2 つのコードセルを実行して、検索結果からコンテキストを取得して出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch context from the response\n",
    "def get_contexts(retrievalResults):\n",
    "    contexts = []\n",
    "    for retrievedResult in retrievalResults: \n",
    "        contexts.append(retrievedResult['content']['text'])\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = get_contexts(retrievalResults)\n",
    "pp.pprint(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### タスク 2.2.3: パーソナライズされた応答をモデルで生成するために特定のプロンプトを使用する \n",
    "\n",
    "このタスクでは、可能な限り事実に基づいた統計情報を使用して質問に回答する、ファイナンシャルアドバイザー AI システムとして機能するように、モデルに特定のプロンプトを使用します。ユーザー**クエリ**と共に、プロンプトの **{contexts}** の一部として前のタスクの **Retrieve** API 応答を指定して、モデルが参照できるようにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 次のコードセルを実行して、モデルがファイナンシャルアドバイザー AI システムとして機能するように、特定のプロンプトを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Human: あなたはファイナンシャルアドバイザーのAIシステムであり、可能な限り事実に基づいた統計情報を用いて質問に答えます。\n",
    "以下の情報を用いて、<question>タグで囲まれた質問に簡潔に回答してください。\n",
    "わからない部分がある場合は、その部分は「わからない」とだけ伝え、わざわざ答えを作ろうとしないでください。\n",
    "<context>\n",
    "{contexts}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{query}\n",
    "</question>\n",
    "\n",
    "回答は具体的なものでなければならず、可能な場合は統計や数字を使用する必要があります。\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### タスク 2.2.4: Amazon Bedrock から基盤モデルを呼び出す\n",
    "\n",
    "このタスクでは、Amazon Bedrock の **amazon.nova-lite-v1:0** 基盤モデルを使用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 次の 2 つのコードセルを実行して、Amazon Bedrock の **amazon.nova-lite-v1:0** 基盤モデルを呼び出します。コンテキストとクエリの両方をモデルに渡します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload with model parameters\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": prompt}]\n",
    "}]\n",
    "\n",
    "# Create the proper Nova Lite payload\n",
    "nova_payload = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"messages\": messages,\n",
    "    \"inferenceConfig\": {\n",
    "        \"maxTokens\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"topP\": 0.9,\n",
    "        \"topK\": 20\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelId = 'amazon.nova-lite-v1:0' # change this to use a different version from the model provider\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock_client.invoke_model(\n",
    "    body=json.dumps(nova_payload),\n",
    "    modelId=modelId,\n",
    "    accept=accept,\n",
    "    contentType=contentType\n",
    ")\n",
    "\n",
    "# Parse and extract the response\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# Extract just the text from the response\n",
    "response_text = ''\n",
    "if 'output' in response_body and 'message' in response_body['output']:\n",
    "    message_content = response_body['output']['message']['content']\n",
    "    if message_content and isinstance(message_content, list):\n",
    "        response_text = message_content[0].get('text', '')\n",
    "\n",
    "# Print the response text\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パート 2: LangChain 統合\n",
    "\n",
    "### タスク 2.3: LangChain 統合\n",
    "\n",
    "このタスクでは、LangChain の **AmazonKnowledgeBasesRetriever** クラスを使用して質問応答アプリケーションを構築します。ナレッジベースにクエリを実行して、類似検索に基づいて必要な数のドキュメントチャンクを取得します。その後、質問に回答するために、それを LangChain チェーンで統合し、ドキュメントチャンクとクエリを llm (**Amazon Nova Lite**) に渡します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### タスク 2.3.1: 環境の設定\n",
    "\n",
    "このタスクでは、環境を設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 次のコードセルを実行して、環境の設定に必要なパッケージをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_community.retrievers import AmazonKnowledgeBasesRetriever\n",
    "\n",
    "llm = ChatBedrock(model_id=modelId, \n",
    "                  client=bedrock_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### タスク 2.3.2: Retrieve API を呼び出す AmazonKnowledgeBasesRetriever オブジェクトを作成する\n",
    "\n",
    "このタスクでは、Amazon Bedrock ナレッジベースによって提供される **Retrieve** API を呼び出す、LangChain の **AmazonKnowledgeBasesRetriever** オブジェクトを作成します。これにより、ユーザーのクエリが埋め込みに変換され、ナレッジベースが検索され、関連する結果が返されるので、セマンティック検索結果に基づいてカスタムワークフローの構築をより細かく制御できるようになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 次のコードセルを実行して **AmazonKnowledgeBasesRetriever** オブジェクトを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"2022年12月31日現在のAnyCompanyのtotal operating lease liabilitiesとtotal sublease incomeはいくらでしたか？\"\n",
    "retriever = AmazonKnowledgeBasesRetriever(\n",
    "        knowledge_base_id=kb_id,\n",
    "        retrieval_config={\"vectorSearchConfiguration\": \n",
    "                          {\"numberOfResults\": 4,\n",
    "                           'overrideSearchType': \"SEMANTIC\", # optional\n",
    "                           }\n",
    "                          },\n",
    "        # endpoint_url=endpoint_url,\n",
    "        # region_name=region,\n",
    "        # credentials_profile_name=\"<profile_name>\",\n",
    "    )\n",
    "docs = retriever.invoke(\n",
    "        input=query\n",
    "    )\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### タスク 2.3.3: パーソナライズされた応答を得るために、モデルに特定のプロンプトを使用する\n",
    "\n",
    "このタスクでは、可能な限り事実に基づいた統計情報を使用して質問に回答する、ファイナンシャルアドバイザー AI システムとして機能するように、モデルに特定のプロンプトを使用します。ユーザー**クエリ**と共に、プロンプトの **{context}** の一部として上記のタスクの **Retrieve** API 応答を指定して、モデルが参照できるようにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.次のコードセルを実行して、モデルがファイナンシャルアドバイザー AI システムとして機能するように、特定のプロンプトを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Human: あなたはファイナンシャルアドバイザーのAIシステムであり、可能な限り事実に基づいた統計情報を用いて質問に答えます。\n",
    "以下の情報を用いて、<question>タグで囲まれた質問に簡潔に回答してください。\n",
    "わからない部分がある場合は、その部分は「わからない」とだけ伝え、わざわざ答えを作ろうとしないでください。\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "回答は具体的なものでなければならず、可能な場合は統計や数字を使用する必要があります。\n",
    "\n",
    "Assistant:\"\"\"\n",
    "nova_prompt = PromptTemplate(template=PROMPT_TEMPLATE, \n",
    "                               input_variables=[\"context\",\"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### タスク 2.3.4: 取得チェーンでリトリーバーと LLM を統合して質問応答アプリケーションを構築する\n",
    "\n",
    "このタスクでは、LangChain Expression Language (LCEL) を使用してリトリーバーと LLM を統合し、質問応答アプリケーションを構築します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.次のセルを実行し、retriever.invoke を使用して取得したドキュメントにリトリーバーと LLM を統合します。結果を出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs): #concatenate the text from the page_content field in the output from retriever.invoke\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | nova_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response=chain.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i aria-hidden=\"true\" class=\"far fa-thumbs-up\" style=\"color:#008296\"></i> **タスクの完了:** このノートブックを完了しました。ラボの次の部分に進むために、以下を実行してください。\n",
    "\n",
    "- このノートブックファイルを閉じます。\n",
    "- ラボセッションに戻り、タスク 3 に進みます。"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
