{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# タスク 3: RAG 評価 (RAGAS) フレームワークを使用し、Amazon Bedrock ナレッジベースを使って質問応答アプリケーションを構築および評価する\n",
    "\n",
    "このタスクでは、LangChain の **AmazonKnowledgeBasesRetriever** クラス、Chains、および応答を評価するための RAGAS フレームワークを使用して、質問応答アプリケーションの構築と評価を行います。ここでは、ナレッジベースにクエリを実行して、類似検索に基づいて必要な数のドキュメントチャンクを取得します。次に、クエリと共にドキュメントチャンクをコンテキストとして指定して、テキスト生成 LLM にプロンプトを出します。次に、「faithfulness (忠実度)」、「answer_relevancy (回答の関連性)」、「context_recall (コンテキスト再現率)」、「context_precision (コンテキスト精度)」、「context_entity_recall (コンテキストエンティティ再現率)」、「answer_similarity (回答類似性)」、「answer_correctness (回答の正確性)」、「harmfulness (有害性)」、「maliciousness (悪意の有無)」、「coherence (一貫性)」、「correctness (正しさ)」、「conciseness (簡潔さ)」という評価メトリクスを使用して応答を評価します。\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-info-circle\" style=\"color:#007FAA\"></i> **詳細:** Ragas フレームワークで使用されるさまざまなメトリクスに関する追加情報については、**[Metrics](https://docs.ragas.io/en/latest/concepts/metrics/index.html)** を参照してください。\n",
    "\n",
    "### パターン\n",
    "\n",
    "検索拡張生成 (RAG) パターンを使用してソリューションを実装します。RAG は、言語モデルの外部からデータを取得し、関連する取得データをコンテキストに追加することでプロンプトを拡張します。このタスクでは、ラボのプロビジョニング中に既に作成済みのナレッジベースを使用して、クエリへの応答を作成します。\n",
    "\n",
    "#### 評価\n",
    "\n",
    "- RAGAS を利用して次のメトリクスを評価します。\n",
    "  - **Faithfulness (忠実度):** 生成された回答の事実の一貫性を、与えられたコンテキストと照らし合わせて測定します。これは、回答と、取得したコンテキストから計算されます。回答は (0,1) の範囲で計測されます。高いほど忠実度が優れています。\n",
    "  - **Answer Relevance (回答の関連性):** このメトリクスは、生成された回答が特定のプロンプトにどの程度関連しているかを評価することに重点を置いています。不完全または冗長な情報を含む回答には低いスコアが割り当てられ、スコアが高いほど関連性が高くなります。このメトリクスは、質問、コンテキスト、および回答を使用して計算されます。実際のところ、スコアの範囲はほとんどの場合 0～1 ですが、コサイン類似度が -1～1 の範囲にあるため、これは数学的に保証されているわけではないことに注意してください。\n",
    "  - **Context Precision (コンテキスト精度):** これは、コンテキストに存在する Ground Truth の関連項目すべてが上位にランクされているかどうかを評価するメトリクスです。理想的には、関連性の高いすべてのチャンクがランク上位に表示される必要があります。このメトリクスは、質問、ground_truth、コンテキストを使用して計算され、値は 0～1 の範囲です。スコアが高いほど精度が高くなります。\n",
    "  - **Context Recall (コンテキスト再現率):** このメトリクスは、取得したコンテキストが注釈付きの回答とどの程度一致しているかを測定し、Ground Truth となる真実として扱います。Ground Truth および取得したコンテキストに基づいて計算され、値の範囲は 0～1 です。値が大きいほどパフォーマンスが高くなります。\n",
    "  - **Context entities recall (コンテキストエンティティ再現率):** このメトリクスは、ground_truths のみに存在するエンティティの数と、ground_truths とコンテキストの両方に存在するエンティティの数との割合に基づいて、取得したコンテキストの再現率を計算します。簡単に言えば、ground_truths から再現されたエンティティの割合を示す指標です。このメトリクスは、観光ヘルプデスクや歴史 QA など、事実に基づくユースケースに役立ちます。このメトリクスは、ground_truths に存在するエンティティとの比較に基づいて、エンティティの検索メカニズムを評価するのに役立ちます。エンティティが重要な場合は、そうしたエンティティを対象とするコンテキストが必要だからです。\n",
    "  - **Answer Semantic Similarity (回答セマンティクス類似性):** 回答セマンティック類似性の概念は、生成された回答と Ground Truth との間の意味的類似性の評価に関係します。この評価は Ground Truth と回答に基づいており、値は 0～1 の範囲に収まります。スコアが高いほど、生成された回答と Ground Truth との整合性が優れています。\n",
    "  - **Answer Correctness (回答の正確性):** 回答の正確性の評価には、生成された回答の正確さを、Ground Truth と比較して測定することが含まれます。この評価は Ground Truth と回答に基づいており、スコアは 0～1 です。スコアが高いほど、生成された回答と Ground Truth との間により近い一致を示し、正確性が高いことを示します。回答の正確性には、生成された回答と Ground Truth との間の意味的類似性と、事実上の類似性という 2 つの重要な要素が含まれます。これらの要素は加重スキームを用いて組み合わされ、回答の正解スコアが算出されます。また、必要に応じて「しきい値」値を使用して結果のスコアを丸めてバイナリにすることもできます。\n",
    "  - **Aspect Critique (アスペクト批評):** これは、無害性や正確性など、事前に定義された要素に基づいて提出物を評価することを目的としています。アスペクト批評の出力はバイナリ形式で、提出物が定義されたアスペクトと一致しているかどうかを示します。この評価は、「回答」を入力として使用して実行されます。\n",
    "\n",
    "このタスクでは、AnyCompany の 10K 財務報告 (合成的に生成されたデータセット) をテキストコーパスとして使用して質問応答を行います。このデータは既に Amazon Bedrock のナレッジベースに取り込まれています。\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **注:** 特定のユースケースでは、ドメイントピックの異なるさまざまなファイルを同期し、同じ方法でこのノートブックにクエリを実行して、Retrieve API を使用してナレッジベースからのモデル応答を評価できます。\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-exclamation-circle\" style=\"color:#7C5AED\"></i> **注意:** [**Run**] メニューの [**Run All Cells**] オプションを使用するよりも、各コードセルを個別に実行することをお勧めします。すべてのセルをまとめて実行すると、カーネルがクラッシュしたり再起動したりするなど、予期しない動作が発生することがあります。セルを 1 つずつ実行することで、実行フローをより適切に制御し、潜在的なエラーを早期に検出し、コードを意図したとおりに実行することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## タスク 3.1: 環境を設定する\n",
    "\n",
    "このノートブックを実行するには、依存関係である LangChain と RAGAS、そして更新された boto3、botocore パッケージをインストールする必要があります。\n",
    "\n",
    "以下に示す手順に従って、必要なパッケージを設定します。\n",
    "\n",
    "- 基盤モデルを呼び出す **bedrock-runtime** を作成するために必要なライブラリをインポートします。\n",
    "- LangChain 関連ライブラリをインポートします。\n",
    "- 大規模言語モデルとして Bedrock モデル **amazon.titan-text-premier-v1:0** を初期化し、RAG パターンを使用してクエリ補完を実行します。\n",
    "- 大規模言語モデルとして Bedrock モデル **amazon.nova-lite-v1:0** を初期化し、RAG 評価を実行します。\n",
    "- 大規模言語埋め込みモデルとして Bedrock モデル **amazon.titan-embed-text-v2:0** を初期化し、RAG 評価用の埋め込みを作成します。これは、ナレッジベースの作成に使用されたのと同じ埋め込みモデルです。\n",
    "- ナレッジベースと統合された LangChain リトリーバーを初期化します。\n",
    "- ノートブックの後半で、LLM とリトリーバーをチェーンとしてまとめて、質問応答アプリケーションを作成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 次のコードセルを実行して、Amazon Bedrock の既存のナレッジベース ID を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "import boto3\n",
    "\n",
    "session = boto3.Session()\n",
    "bedrock_client = session.client('bedrock-agent')\n",
    "\n",
    "try:\n",
    "    response = bedrock_client.list_knowledge_bases(\n",
    "        maxResults=1  # We only need to retrieve the first Knowledge Base\n",
    "    )\n",
    "    knowledge_base_summaries = response.get('knowledgeBaseSummaries', [])\n",
    "\n",
    "    if knowledge_base_summaries:\n",
    "        kb_id = knowledge_base_summaries[0]['knowledgeBaseId']\n",
    "        print(f\"Knowledge Base ID: {kb_id}\")\n",
    "    else:\n",
    "        print(\"No Knowledge Base summaries found.\")\n",
    "        \n",
    "except botocore.exceptions.ClientError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 次のコードセルを実行して依存関係をインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_community.retrievers import AmazonKnowledgeBasesRetriever\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "\n",
    "llm_for_text_generation = ChatBedrock(model_id=\"amazon.nova-lite-v1:0\", client=bedrock_client)\n",
    "llm_for_evaluation = ChatBedrock(model_id=\"amazon.nova-lite-v1:0\", client=bedrock_client)\n",
    "\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\",client=bedrock_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## タスク 3.2: LangChain から **AmazonKnowledgeBasesRetriever** オブジェクトを作成する\n",
    "\n",
    "このタスクでは、LangChain から **AmazonKnowledgeBasesRetriever** オブジェクトを作成してナレッジベースを検索し、関連する結果を返します。これにより、セマンティクス検索結果に基づいてカスタムワークフローをより詳細に構築できるようになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 次のコードセルを実行して **AmazonKnowledgeBasesRetriever** オブジェクトを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = AmazonKnowledgeBasesRetriever(\n",
    "        knowledge_base_id=kb_id,\n",
    "        retrieval_config={\"vectorSearchConfiguration\": {\"numberOfResults\": 5}},\n",
    "        # endpoint_url=endpoint_url,\n",
    "        # region_name=\"us-east-1\",\n",
    "        # credentials_profile_name=\"<profile_name>\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## タスク 3.3: RetrievalQA チェーンを使用してモデルを呼び出し、応答を生成する \n",
    "\n",
    "このタスクでは、次の情報を使用してモデルを呼び出し、応答を視覚化します。\n",
    "\n",
    "質問 =\n",
    "\n",
    "```\n",
    "AnyCompany の財務に関するいくつかのリスクのリストを、説明なしの番号付きリストで提供します。\"\n",
    "```\n",
    "\n",
    "Ground Truth 回答 = \n",
    "\n",
    "```\n",
    "1. 商品価格\n",
    "2. 外国為替レート \n",
    "3. 株価\n",
    "4. 信用リスク\n",
    "5. 流動性リスク\n",
    "...\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 次のコードセルを実行して、コンテキストと質問を変数とするプロンプトを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Human: あなたはファイナンシャルアドバイザーのAIシステムであり、可能な限り事実に基づいた統計情報を用いて質問に答えます。\n",
    "以下の情報を用いて、<question>タグで囲まれた質問に簡潔に回答してください。\n",
    "わからない部分がある場合は、その部分は「わからない」とだけ伝え、わざわざ答えを作ろうとしないでください。\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "回答は具体的なものでなければならず、可能な場合は統計や数字を使用する必要があります。\n",
    "\n",
    "Assistant:\"\"\"\n",
    "prompt = PromptTemplate(template=PROMPT_TEMPLATE, \n",
    "                               input_variables=[\"context\",\"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 次のコードセルを実行して、定義済みのクエリを使用してモデルを呼び出し、結果を出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs): #concatenate the text from the page_content field in the output from retriever.invoke\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm_for_text_generation\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "query = \"AnyCompanyの財務リスク10項目を番号付きリストで提供してください。説明は含めないでください。\"\n",
    "\n",
    "response=chain.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## タスク 3.4: 評価データを準備する\n",
    "\n",
    "RAGAS は参照不要の評価フレームワークを目指しているため、評価データセットの準備は最小限で済みます。このタスクでは、次に示すように、**question** と **ground_truths** のペアを用意し、そこから推論によって以下のように残りの情報を準備します。\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **注:** **context_recall** メトリクスを調べる必要がない場合は、**ground_truths** 情報を提供する必要はありません。このタスクで準備する必要があるのは、**question** だけとなります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 次のコードセルを実行して、評価のための **question** と **ground_truths** のペアを準備します。この処理は、スロットリングが発生した場合には再試行しながら、数分間実行される可能性があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Define questions and ground truths for RAGAS evaluation\n",
    "questions = [\n",
    "    \"2021 年に AnyCompany Financial の営業活動による純現金が増加した主な理由は何ですか?\",\n",
    "    \"AnyCompany Financial の投資活動における純現金使用が最も高かったのはどの年ですか。主な理由は何ですか。\",\n",
    "    \"2021 年の AnyCompany Financial の財務活動によるキャッシュインフローの主な源泉は何でしたか?\",\n",
    "    \"2020 年から 2021 年にかけての AnyCompany Financial の現金および現金同等物の前年比変化率を計算します。\",\n",
    "    \"提供された情報に基づいて、AnyCompany Financial の全体的な財務状況と成長の見通しについてどのようなことが推測できますか?\"\n",
    "]\n",
    "\n",
    "ground_truth = [\n",
    "    \"営業活動による純キャッシュ・フローの増加は、主に純利益の増加と営業資産および負債の好ましい変動によるものです。\",\n",
    "    \"AnyCompany Financialの2021年の投資活動における純現金使用額は3億6,000万ドルで、2020年の2億9,000万ドル、2019年の2億4,000万ドルと比較して過去最高となりました。主な理由は、有形固定資産および市場性ある有価証券の購入の増加です。\",\n",
    "    \"2021 年の AnyCompany Financial の財務活動によるキャッシュインフローの主な源泉は、普通株式および長期債務の発行による収入の増加でした。\",\n",
    "    \"2020年から2021年にかけての現金および現金同等物の前年比変化率を計算する: \\\n",
    "    2020年の現金および現金同等物：3億5000万ドル \\\n",
    "    2021年の現金および現金同等物：4億8000万ドル \\\n",
    "    パーセンテージの変化 = (2021 value - 2020 value) / 2020 value * 100 \\\n",
    "    = ($480 million - $350 million) / $350 million * 100 \\\n",
    "    = 37.14% increase\",\n",
    "    \"提供された情報に基づくと、AnyCompany Financialは健全な財務状況にあり、良好な成長見通しを有していると考えられます。同社は営業活動による純キャッシュフローが増加しており、高い収益性と運転資本の効率的な運用を示しています。AnyCompany Financialは有形固定資産や有価証券などの長期資産への投資を行っており、これは将来の成長と拡大に向けた計画を示唆しています。同社は普通株式の発行と長期債務の発行を通じて成長資金を調達しており、これは投資家と貸し手からの信頼を示しています。全体として、AnyCompany Financialの過去3年間の現金および現金同等物の着実な増加は、将来の成長と投資機会のための強固な基盤となっています。\"\n",
    "]\n",
    "\n",
    "def get_model_response(query, chain, retriever, max_retries=5, wait_time=15):\n",
    "    \"\"\"Get response from the model with fixed wait time between retries\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Configure Nova Lite with increased tokens\n",
    "            nova_config = {\n",
    "                \"schemaVersion\": \"messages-v1\",\n",
    "                \"messages\": [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"text\": query}]\n",
    "                }],\n",
    "                \"inferenceConfig\": {\n",
    "                    \"maxTokens\": 2048,\n",
    "                    \"temperature\": 0.5,\n",
    "                    \"topP\": 0.9,\n",
    "                    \"topK\": 20\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Try to invoke with config override\n",
    "            try:\n",
    "                answer = chain.invoke(\n",
    "                    query,\n",
    "                    config_override={\"model_kwargs\": nova_config}\n",
    "                )\n",
    "            except AttributeError:\n",
    "                # If config_override doesn't work, try direct invocation\n",
    "                answer = chain.invoke(query)\n",
    "            \n",
    "            context = [docs.page_content for docs in retriever.invoke(query)]\n",
    "            print(f\"Successfully processed query on attempt {attempt + 1}\")\n",
    "            return answer, context\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"Failed after {max_retries} attempts for query: {query[:50]}...\")\n",
    "                print(f\"Error: {str(e)}\")\n",
    "                return None, None\n",
    "            print(f\"Attempt {attempt + 1} failed, waiting {wait_time} seconds before retry...\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "# Process questions one at a time with fixed delay\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "print(\"Starting to process questions...\")\n",
    "for i, query in enumerate(questions, 1):\n",
    "    print(f\"\\nProcessing question {i}/{len(questions)}\")\n",
    "    print(f\"Query: {query[:100]}...\")\n",
    "    \n",
    "    answer, context = get_model_response(query, chain, retriever)\n",
    "    if answer is not None:\n",
    "        answers.append(answer)\n",
    "        contexts.append(context)\n",
    "        print(f\"Successfully processed question {i}\")\n",
    "    else:\n",
    "        print(f\"Failed to process question {i}\")\n",
    "    \n",
    "    #if i < len(questions):\n",
    "    #    print(f\"Waiting 60 seconds before next question...\")\n",
    "    #    time.sleep(60)\n",
    "\n",
    "# Create dataset for RAGAS evaluation\n",
    "data = {\n",
    "    \"question\": questions[:len(answers)],\n",
    "    \"ground_truth\": ground_truth[:len(answers)],\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts\n",
    "}\n",
    "\n",
    "# Convert to dataset\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "# Print dataset information\n",
    "print(\"\\nDataset Creation Summary:\")\n",
    "print(f\"Total questions processed: {len(dataset)} out of {len(questions)}\")\n",
    "print(f\"Columns available: {dataset.column_names}\")\n",
    "\n",
    "# Print sample entry\n",
    "if len(dataset) > 0:\n",
    "    print(\"\\nSample Entry (First Question):\")\n",
    "    print(f\"Question: {dataset[0]['question']}\")\n",
    "    print(f\"Ground Truth: {dataset[0]['ground_truth']}\")\n",
    "    print(f\"Model Answer: {dataset[0]['answer']}\")\n",
    "else:\n",
    "    print(\"\\nNo entries were successfully processed into the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 次のコードセルを実行して、LLM からの回答と、一連の質問評価のための Ground Truth を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for answer in answers:\n",
    "    i=i+1\n",
    "    print(str(i)+').'+questions[i-1]+'\\n')\n",
    "    print(\"LLM:\" +answer+'\\n')\n",
    "    print (\"Ground truth: \"+ ground_truth[i-1]+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## タスク 3.5: RAG アプリケーションを評価する\n",
    "\n",
    "このタスクでは、使用したいすべてのメトリクスを **ragas.metrics** からインポートします。次に、**evaluate()** 関数を使用して、関連するメトリクスと準備したデータセットをそのまま渡します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 次のコードセルを実行して **ragas.metrics** からすべてのメトリクスをインポートし、**evaluate()** 関数を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore')   # ignore warnings related to pydantic v1 to v2 migration\n",
    "logging.getLogger('root').setLevel(logging.CRITICAL)\n",
    "\n",
    "from datasets import Dataset\n",
    "if not hasattr(Dataset, 'from_list'):\n",
    "    def from_list_compatibility(data_list):\n",
    "        if isinstance(data_list, list) and len(data_list) > 0 and isinstance(data_list[0], dict):\n",
    "            keys = data_list[0].keys()\n",
    "            data_dict = {key: [item[key] for item in data_list] for key in keys}\n",
    "            return Dataset.from_dict(data_dict)\n",
    "        return Dataset.from_dict({})\n",
    "    Dataset.from_list = staticmethod(from_list_compatibility)\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_entity_recall,\n",
    "    answer_similarity,\n",
    "    answer_correctness\n",
    ")\n",
    "\n",
    "from ragas.metrics.critique import (\n",
    "harmfulness, \n",
    "maliciousness, \n",
    "coherence, \n",
    "correctness, \n",
    "conciseness\n",
    ")\n",
    "\n",
    "#specify the metrics here\n",
    "metrics = [\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        context_entity_recall,\n",
    "        answer_similarity,\n",
    "        answer_correctness,\n",
    "        harmfulness, \n",
    "        maliciousness, \n",
    "        coherence, \n",
    "        correctness, \n",
    "        conciseness\n",
    "    ]\n",
    "\n",
    "try:\n",
    "    result = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=metrics,\n",
    "        llm=llm_for_evaluation,\n",
    "        embeddings=bedrock_embeddings,\n",
    "    )\n",
    "    df = result.to_pandas()\n",
    "except Exception as e:\n",
    "    # Handle any exceptions that occur during the evaluation\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i aria-hidden=\"true\" class=\"fas fa-exclamation-circle\" style=\"color:#7C5AED\"></i> **注意:** 上の出力の警告は無視しても問題ありません。次に進む前に、評価が 100% 完了していることを確認してください。このステップは完了するまでに約 7～10 分かかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 以下のコードセルを実行して、結果の RAGAS スコアを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 10\n",
    "df.style.set_sticky(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 以下のコードセルを実行して、結果の RAGAS スコアを Excel 形式でエクスポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.style.to_excel('styled.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **注:** 上のコードセルを正常に実行すると、左側のナビゲーションペインの **ja_jp** フォルダの下に **styled.xlsx** という名前の確認用のファイルが表示されるはずです。ファイルを開くのに時間がかかりすぎる場合は、ファイルを右クリックして [**Open in New Browser Tab**] を選択します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **注:** 上のスコアは、RAG アプリケーションのパフォーマンスを相対的に評価するものであり、単独のスコアとしてではなく、慎重に使用する必要があることに注意してください。また、評価に使用した質問と回答のペアは 5 つだけであることにも注意してください。ベストプラクティスとして、モデルを評価する際は、ドキュメントのさまざまな要素をカバーするのに十分なデータを使用する必要があります。\n",
    "\n",
    "スコアに基づいて RAG ワークフローの他のコンポーネントを確認すると、スコアをさらに最適化できます。推奨されるオプションとしては、チャンキング戦略やプロンプト命令を見直すこと、コンテキスト追加のために numberOfResults を大きくすることなどがあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i aria-hidden=\"true\" class=\"far fa-thumbs-up\" style=\"color:#008296\"></i> **タスクの完了:** このノートブックを完了しました。ラボの次の部分に進むために、以下を実行してください。\n",
    "\n",
    "- このノートブックファイルを閉じます。\n",
    "- ラボセッションに戻り、タスク 4 に進みます。"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
